dim(mrg)
head(mrg)
points(mrg, plot(rep(1, 52), mrg[,2], xlim = c(.5, 2.5)))
with(mrg, plot(rep(1, 52), mrg[,2], xlim = c(.5, 2.5)))
with(mrg, points(rep(2, 52), mrg[,3], mrg))
with(mrg, points(rep(2, 52), mrg[,3]))
segments()
with(mrg, points(rep(2, 52), mrg[,3]))
segments(rep(1, 52), mrg[, 2], rep(2, 52), mrg[,3])
mrg[mrg$mean.x < mrg$mean.y, ]
require(downloader)
dataset_url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
download(dataset_url, dest = "data.zip", mode = "wb")
unzip("data.zip", exdir = "./")
NEI <- readRDS("summarySCC_PM25.rds")
SCC <- readRDS("Source_Classification_Code.rds")
findata <- with(NEI, aggregate(Emissions, by = list(year), sum))
install.packages("markdown")
load(markdown)
installed.packages()
markdown
markdown()
library(markdown)
install.packages(c("curl", "jsonlite", "R6", "Rcpp", "spam", "tibble"))
install.packages(c("curl", "jsonlite", "R6", "Rcpp", "spam", "tibble"))
library(swirl)
swirl()
myplot(2)
myplot(20)
myplot2(2)
qt(.975, 2)
myplot2(20)
sleep
range(g1)
range(g2)
difference <-g2 - g1
mean(difference)
s <-sd(difference)
mn + c(-1, 1) * qt(.975, 1) * s / sqrt(10)
mn + c(-1, 1) * qt(.975, 9) * s / sqrt(10)
t.test(difference)
t.test(difference)$conf.int
sp <- 7*132.86^2 + 20*127.44^2
sp <- 7*15.34^2 + 20*18.23^2
ns <- 27
sp <- sp / ns
sp <- sqrt(sp / ns)
132.86+127.44 + c(-1, 1) * sp*sqrt(1/8 + 1/21)
132.86+127.44 + c(-1, 1) * qt(.975, ns) * sp*sqrt(1/8 + 1/21)
132.86 - 127.44 + c(-1, 1) * qt(.975, ns) * sp*sqrt(1/8 + 1/21)
sqrt((g1 + g1)/18)
sp <- sqrt((9*var(g1) + 9 * var(g2)) / 18)
sp * (2/ 10)
md + c(-1, 1 * qt(.975, 18) * sp * sqrt(1/5))
md + c(-1, 1) * qt(.975, 18) * sp * sqrt(1/5)
t.test(g2, g1, paired = FALSE, var.equal = TRUE)$conf
t.test(g2, g1, paired = TRUE, var.equal = TRUE)$conf
t.test(g2, g1, paired = TRUE)$conf
(15.34/21 + 18.23/21)^2
num <- (15.34^2/21 + 18.23^2/21)
num <- (15.34^2/8 + 18.23^2/21)
num <- (15.34^2/8 + 18.23^2/21)^2
15.34/(8^2)/7 + 18.23^2/(21^2)/20
den <- 15.34/(8^2)/7 + 18.23^2/(21^2)/20
den <- 15.34^4/(8^2)/7 + 18.23^4/(21^2)/20
mydf <- num / den
qt(.975, mydf)
132.86 - 127.44 + c(-1, 1) * qt(.975, mydf) * sqrt(15.34^2 / 8 + 18.23^2/21)
10 / sqrt(32)
10/sqrt(100)
(32 -30)/ 1
(32 - 30)/(10/4)
4
15
qt(.85, 15)
qt(.95, 15)
dim(fs)
?t.test
t.test(fs$sheight-fs$fheight)
11.7885 * sd(fs$sheight - fs$fheight) / sqrt(1078)
mybin
0
8
pt(q = 2.5, df = 15)
pt(q = 2.5, df = 15. lower.tail = FALSE)
pt(q = 2.5, df = 15, lower.tail = FALSE)
qnorm(.95)
qt(.99)
qnorm(.99)
pnorm(2)
pnrom(2, lower.tail = FALSE)
pnorm(2, lower.tail = FALSE)
my
mybin
pbinom(6, size = 8, prob = .5, lower.tail = FALSE)
pbinom(7, size = 8, prob = .5, lower.tail = FALSE)
pbinom(7, size = 8, prob = .5, lower.tail = TRUE)
ppois(9, 5, lower.tail = FALSE)
a <- 1100
s = 30
s <- 30
n <- 9
error <- qt(0.975, df = n - 1) * s / sqrt(n)
left <- a - error
right <- a + error
left
right
n <- 9
mn <- -2
quant <- 0.975
ci_up = 0
right <- 0
sigma <- (right - mn * sqrt(n))/ qt(quant, df = n - 1)
sigma
mnNew <- 3
sdNew <- 0.6
mnOld <- 5
sdOld <- 0.68
confInt <- .95
nNew <- 10
nOld <- 10
o_p < sqrt((nOld - 1) * sdOld + (nNew - 1) * sdNew)/ 18
o_p <- sqrt((nOld - 1) * sdOld + (nNew - 1) * sdNew)/ 18
confInt <- mnNew - mnOld + c(-1, 1) * qt(confInt, 18) * o_p * sqrt(1 / 5)
confInt
library(swirl)
swirl()
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
z <- qnorm(.95)
pnorm(30 + z, mean = 30)
pnorm(30 + z, mean = 30, lower.tail = FALSE)
pnorm(30 + z, mean = 32, lower.tail = FALSE)
pnorm(30 + z, sd = 1, mean = 32, lower.tail = FALSE)
pnorm(30 + z^2, sd = 2, mean = 32, lower.tail = FALSE)
pnorm(30 + z^2, mean = 32, sd = 2, lower.tail = FALSE)
pnorm(30+z^2, mean = 32, sd = 2, lower.tail = FALSE)
pnorm(30+z^2, mean=32, sd=2, lower.tail=FALSE)
pnorm(30+z*2, mean=32, sd=2, lower.tail=FALSE)
power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 16, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 16, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$power
power.t.test(power = .8, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$n
power.t.test(power = .8, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$n
power.t.test(power = .8, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$n
power.t.test(power = .8, n = 26, sd = 1, type = "one.sample", alt = "one.sided")$delta
power.t.test(power = .8, n = 27, sd = 1, type = "one.sample", alt = "one.sided")$delta
head(pValues)
sum(pValues < .05)
p.adjust(pValues, method = "bonferonni")
p.adjust(pValues, method = "bonferroni")
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
sum(p.adjust(pValues, method = "BH") < 0.05)
tail(trueStatus)
table(pValues2 < .05, trueStatus)
24/476
24/500
table(p.adjust(pValues2, method = "bonferroni" < .05), trueStatus)
table(p.adjust(pValues2, method = "bonferroni") < .05, trueStatus)
table(p.adjust(pValues2, method = "BH") < .05, trueStatus)
for (x %in% 1:6) sum(x * 1/6)
for (x in 1:6) sum(x * 1/6)
sum(1:6)/6
print(g2)
head(sh)
nh
median(resampledMeadians)
median(resampledMedians)
median(sh)
sam <- sample(fh, nh * B, replace = TRUE)
matrix(sam, B, nh)
resam <- matrix(sam, B, nh)
meds <- apply(resam, 1, median)
median(fh) - median(meds)
sd(meds)
sd(resampledMedians)
quantile(resampledMedians, c(.025, .975))
quantile(meds, c(.025, .975))
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCounts
BCcounts
group
testStat
obs <- testStat(BCcounts, group)
obs
mean(Bdata$count - Cdata$count)
sample(group)
perms <- sapply(1 : 10000, function(i), testStat(BCcounts, sample(group)))
perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))
mean(perms > obs)
testStat(DEcounts, group)
perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
swirl()
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility)
1
mdl <- lm(Fertility ~., swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ Examination, swiss)
mdl2 <- lm(Fertility ~ -Examination, swiss)
mdl2 <- lm(Fertility ~. -Examination, swiss)
vif(mdl2)
x1c
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~. Agriculture, swiss)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture, Examination, Education, swiss)
fit3 <- lm(Fertility ~ Agriculture, Education, swiss)
fit3 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- deviance(fit1) - deviance(fit3)
n <- deviance(fit1) - deviance(fit3)/2
n <- (deviance(fit1) - deviance(fit3))/2
F <- n / d
n /d
pf(n/d, 2, 43, lower.tail = FALSE)
shapio.test(fit3$residuals)
1
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
View(ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family = "binomial", data = "ravenData")
mdl <- glm(ravenWinNum ~ ravenScore, family = "binomial", ravenData)
predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds) / (1 + exp(lodds))
summary(mdl)
confint(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
nxt()
View(hits)
class(hits[, 'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
mdl$fitted.values[704]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl <- log(visits + 1)
mdl <- glm(visits ~ date, poisson, hits, offset = log(visits + 1))
mdl <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
summary(mdl1)
qpois(.95, mdl2$fitted.values[704])
knit_with_parameters('C:/Users/ashle/Desktop/Coursera/Regression Models/Course Project.Rmd')
data(kernlab)
library(kernlab)
library(KernSmooth)
data(spam)
library(kernlab)
install.packages(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
set.seed(333)
smallSpam <- spam[sample(dim(spam))[1], size = 10, ]
smallSpam <- spam[sample(dim(spam)[1], size = 10), ]
spamLabel <- (smallSpam$type = "spam") * 1 + 1
spamLabel <- (smallSpam$type == "spam") * 1 + 1
plot(smallSpam$capitalAve, col = spamLabel)
rule1 <- function(x) {}
rule1 <- function(x) {
prediction <- rep(NA, length(x))
prediction[x > 2.7] <- "spam"
prediction[x < 2.4] <- "nonspam"
prediction[(x >= 2.4 & x <= 2.45)] <- "spam"
prediction[(x > 2.45 & x <= 2.7)] <- "nonspam"
return(prediction)
}
table(rule(smallSpam$capitalAve), smallSpam$type)
prediction <- rep(NA, length(x))
> table(rule(smallSpam$capitalAve), smallSpam$type)
table(rule(smallSpam$capitalAve), smallSpam$type)
rule1 <- function(x) {
prediction <- rep(NA, length(x))
prediction[x > 2.7] <- "spam"
prediction[x < 2.4] <- "nonspam"
prediction[(x >= 2.4 & x <= 2.45)] <- "spam"
prediction[(x > 2.45 & x <= 2.7)] <- "nonspam"
return(prediction)
}
table(rule1(smallSpam$capitalAve), smallSpam$type)
rule2 <- function(x) {
prediction <- rep(NA, length(x))
prediction[x > 2.7] <- "spam"
prediction[x < 2.4] <- "nonspam"
return(prediction)
}
table(rule2(smallSpam$capitalAve), smallSpam$type)
table(rule2(spam$capitalAve), smallSpam$type)
sum(rule1(spam$capitalAve)==spam$type)
sum(rule2(spam$capitalAve)==spam$type)
table(rule2(spam$capitalAve)==smallSpam$type)
table(rule2(smallSpam$capitalAve)==smallSpam$type)
library(ISLR)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(caret)
install.packages("caret")
library(caret)
library(ISLR)
data(Wage)
summary(Wage)
inTrain <- createDataPArtition(y=Wage$wage, p=0.7, list=FALSE)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[,c("age", "education","jobclass")], y = training$wage, plot="pairs")
qplot(age, wage, data=training)
qplot(age, wage, colour=jobclass,data=training)
qq <- qplot(age, wage, colour=education,data=training)
qq+ geom_smooth(method='lm', formula=y~x)
cutWage <- cut2(training$wage, g=3)
install.packages("Hmisc")
library(Hmisc)
cutWage <- cut2(training$wage, g=3)
table(cutWage)
p1 <- qplot(cutWaage, age, data=training, fill=cutWage, geom=c("boxplot"))
p1
p1 <- qplot(cutWage, age, data=training, fill=cutWage, geom=c("boxplot"))
p1
p2 <- qplot(cutWage, age, data=training, fill=cutWage, geom=c("boxplot", "jitter"))
grid.arrage(p1, p2, ncol=2)
grid.arrange(p1, p2, ncol=2)
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
t1 <- table(cutWage, training$jobclass)
t1
prop.table(t1, 1)
prop.table(t1, 2)
qplot(wage, colorur=education, data=training, geom="density")
qplot(wage, colour=education, data=training, geom="density")
Make your plots only in the training set. Do not use the test set for exploration.
hist(training$capitalAve, main="",xlab="ave. capital run length")
hist(training$capitalAve, main="", xlab="ave. capital run length")
mean(training$capitalAve)
training <- Wage[inTrain,]
hist(training$capitalAve, main="", xlab="ave. capital run length")
mean(training$capitalAve)
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
hist(training$capitalAve, main="", xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
Skewed and highly variable data needs to be standardized.
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve)) / sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAve)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testcapAve - mean(trainCapAve))/sd(trainCapAve)
testCapAveS <- (testCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58], method =c("center", "scale"))
trainCapAveS <- predict(preObj, training[,-58]$capitalAve)
trainCapAveS <- predict(preObj, training[,-58])$capitalAve)
trainCapAveS <- predict(preObj, training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- predict(preObj, testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(Type ~., data=training, preProcess="center", "scale"), method="glm")
modelFit <- train(Type ~., data=training, preProcess=c("center", "scale"), method="glm")
modelFit <- train(type ~., data=training, preProcess=c("center", "scale"), method="glm")
install.packages("e1071")
library(e1071)
modelFit <- train(type ~., data=training, preProcess=c("center", "scale"), method="glm")
modelFit
spam$capitalAveSq <- spam$capitalAve^2
library(swirl)
swirl()
exit()
0
clear
clear()
clear?
?
1
?clear
library(kernlab);data(spam)
spam$capitalAveSq <- spam$capitalAve^2
head(spam)
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing<-[-inTrain,]
training <- Wage[inTrain,]; testing<-Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass, data=training)
head(predict(dummies, dewdata=training))
head(predict(dummies, newdata=training))
nsv <- newZeroVar(training, saveMetrics = TRUE)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
library(splines)
bsBasis <- bs(training$age, df = 3)
bsBasis
lm1 <- lm(wage ~ bsBasis, data=training)
plot(training$age, training$wage, pch=19, cex-0.5)
plot(training$age, training$wage, pch=19, cex=0.5)
points(training$age, predict(lm1, newdata=training), col="red", pch=20)
predit(bsBasis, age=testing$age)
predict(bsBasis, age=testing$age)
M<-abs(cor(training[,-58]))
M<-abs(cor(training[,-58]))
names(spam)[c(34, 32)]
plot(spam[,34], spam[,32])
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage, select=c(logwage)
)
summary(Wage)
inTrain <-createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
data(Wage)
inTrain <-createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <-Wage[inTrain,]
testing<-Wage[-inTrain,]
featurePlot(x=training[,c("age, "education, "jobclass")], y=training$wage, plot="pairs")
featurePlot(x=training[,c("age", "education", "jobclass")], y=training$wage, plot="pairs")
qplot(age, wage, data=training)
qplot(age, wage, colorur=jobclass, data=training)
qplot(age, wage, colour=jobclass, data=training)
qplot(age, wage, colour=educatin, data=training)
qplot(age, wage, colour=education, data=training)
modFit <- train(wage ~ age + jobclass + education, method="lm", data=training)
finMod <- modFit $finalModel
print(modFit)
plot(finMod, 1, pch=19, cex=0.5, col="#00000010")
qplot(finMod$fitted, finMod$residuals, colour=race, data=training)
plot(finMod$residuals, pch=19)
pred <- predict(modFit, testing)
qplot(wage, pred, colour=year, data=testing)
modFitAll <-train(wage ~ ., data=training, method="lm")
pred <- predict(modFitAll, testing)
qplot(Wage, pred, data=testing)
qplot(wage, pred, data=testing)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
?cut2
library(Hmisc)
?cut2
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") + theme_bw()
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=10))
training <- mutate(training, index=1:nrow(training))
cutIndex <- cut2(training$index, g=10)
breaks <- 10
index=1:nrow(training)
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=10))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer, breaks=20)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("leaflet")
install.packages("RCurl")
install.packages("RCurl")
setwd("C:/Users/ashle/Desktop/Coursera/Practical Machine Learning/Final Project")
